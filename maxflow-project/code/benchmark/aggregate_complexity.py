"""Aggregate empirical complexity scaling metrics from existing benchmark CSVs.

Outputs a CSV `empirical_complexity_summary.csv` into the project `results/` folder
with per-algorithm estimated scaling exponents (log-log slopes) for:
  - Time vs n (sparse, m≈3n)
  - Time vs n (dense, m≈n^2/4)
  - Time vs m (fixed n=200 density sweep)
  - Time vs density (fixed n=200)
  - Time vs Cmax (capacity range experiment)

Method: For each relation we perform a simple least-squares linear regression on
log(variable) vs log(MeanTime) filtering out non-positive runtimes.

This gives an approximate empirical exponent: time ≈ k * variable^slope.

Note: Because each dataset only has a single trial (MeanTime from 1 run) and small
sample counts, treat slopes as indicative, not statistically rigorous.
"""
from __future__ import annotations
import os
import math
import pandas as pd
from typing import Dict, List

SCRIPT_DIR = os.path.dirname(__file__)
PROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, "..", ".."))  # .../code -> project root
RESULTS_DIR = os.path.join(PROJECT_ROOT, "results")
OUTPUT_FILE = os.path.join(RESULTS_DIR, "empirical_complexity_summary.csv")

# Expected input CSVs (already generated by plot_results.py or existing)
FILES = {
    "sparse": os.path.join(RESULTS_DIR, "size_sweep_edgefactor3.csv"),
    "dense": os.path.join(RESULTS_DIR, "size_sweep_dense.csv"),
    "edge": os.path.join(RESULTS_DIR, "edge_sweep_n200.csv"),
    "capacity_dist": os.path.join(RESULTS_DIR, "capacity_distribution_experiment.csv"),
}

# Optional: If capacity range dataset exists (ff/cs scaling)
OPTIONAL_FILES = {
    "capacity_range_ff_cs": os.path.join(RESULTS_DIR, "capacity_range_ff_cs.csv"),
}

def _regression_loglog(x_vals: List[float], y_vals: List[float]) -> float | None:
    """Return slope of log(y) vs log(x) using least squares. Ignore non-positive."""
    pts = [(x, y) for x, y in zip(x_vals, y_vals) if x > 0 and y > 0]
    if len(pts) < 2:
        return None
    logx = [math.log(p[0]) for p in pts]
    logy = [math.log(p[1]) for p in pts]
    mean_x = sum(logx) / len(logx)
    mean_y = sum(logy) / len(logy)
    num = sum((lx - mean_x) * (ly - mean_y) for lx, ly in zip(logx, logy))
    den = sum((lx - mean_x) ** 2 for lx in logx)
    if den == 0:
        return None
    return num / den


def load_csv(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        raise FileNotFoundError(f"Required dataset missing: {path}")
    return pd.read_csv(path)


def compute_sparse_scaling(df: pd.DataFrame) -> Dict[str, float]:
    out = {}
    for algo in df["Algorithm"].unique():
        sub = df[df["Algorithm"] == algo]
        slope = _regression_loglog(sub["Nodes"].tolist(), sub["MeanTime"].tolist())
        out[algo] = slope
    return out


def compute_dense_scaling(df: pd.DataFrame) -> Dict[str, float]:
    out = {}
    for algo in df["Algorithm"].unique():
        sub = df[df["Algorithm"] == algo]
        slope = _regression_loglog(sub["Nodes"].tolist(), sub["MeanTime"].tolist())
        out[algo] = slope
    return out


def compute_edge_scaling(df: pd.DataFrame) -> Dict[str, float]:
    out = {}
    for algo in df["Algorithm"].unique():
        sub = df[df["Algorithm"] == algo]
        slope = _regression_loglog(sub["Edges"].tolist(), sub["MeanTime"].tolist())
        out[algo] = slope
    return out


def compute_density_scaling(df: pd.DataFrame) -> Dict[str, float]:
    out = {}
    for algo in df["Algorithm"].unique():
        sub = df[df["Algorithm"] == algo]
        slope = _regression_loglog(sub["Density"].tolist(), sub["MeanTime"].tolist())
        out[algo] = slope
    return out


def compute_capacity_range_scaling(df: pd.DataFrame) -> Dict[str, float]:
    # Map capacity type to numeric Cmax
    mapping = {"low": 10, "medium": 100, "high": 1000}
    df = df.copy()
    df["Cmax"] = df["CapacityType"].map(mapping)
    out = {}
    for algo in df["Algorithm"].unique():
        sub = df[df["Algorithm"] == algo]
        slope = _regression_loglog(sub["Cmax"].tolist(), sub["MeanTime"].tolist())
        out[algo] = slope
    return out


def compute_ff_cs_capacity_scaling(df: pd.DataFrame) -> Dict[str, float]:
    out = {}
    for algo in df["Algorithm"].unique():
        sub = df[df["Algorithm"] == algo]
        slope = _regression_loglog(sub["Cmax"].tolist(), sub["MeanTime"].tolist())
        out[algo] = slope
    return out


def main():
    sparse_df = load_csv(FILES["sparse"])  # Nodes, Edges
    dense_df = load_csv(FILES["dense"])    # Nodes, Edges, Density
    edge_df = load_csv(FILES["edge"])      # Nodes fixed, varying Edges & Density
    cap_dist_df = load_csv(FILES["capacity_dist"])  # CapacityType

    sparse_scaling = compute_sparse_scaling(sparse_df)
    dense_scaling = compute_dense_scaling(dense_df)
    edge_scaling = compute_edge_scaling(edge_df)
    density_scaling = compute_density_scaling(edge_df)
    cap_range_scaling = compute_capacity_range_scaling(cap_dist_df)

    ff_cs_scaling = {}
    if os.path.exists(OPTIONAL_FILES["capacity_range_ff_cs"]):
        ff_cs_df = load_csv(OPTIONAL_FILES["capacity_range_ff_cs"])
        ff_cs_scaling = compute_ff_cs_capacity_scaling(ff_cs_df)

    # Union of all algorithm names encountered
    algos = set(sparse_scaling) | set(dense_scaling) | set(edge_scaling) | set(density_scaling) | set(cap_range_scaling) | set(ff_cs_scaling)

    rows = []
    for algo in sorted(algos):
        rows.append({
            "Algorithm": algo,
            "slope_time_vs_n_sparse": sparse_scaling.get(algo),
            "slope_time_vs_n_dense": dense_scaling.get(algo),
            "slope_time_vs_m_n200": edge_scaling.get(algo),
            "slope_time_vs_density_n200": density_scaling.get(algo),
            "slope_time_vs_Cmax": cap_range_scaling.get(algo),
            "slope_time_vs_Cmax_ff_cs_dataset": ff_cs_scaling.get(algo),
            "mean_time_n200_sparse": sparse_df[sparse_df["Algorithm"] == algo].loc[sparse_df["Nodes"] == 200, "MeanTime"].mean() if 200 in sparse_df["Nodes"].values else None,
            "mean_time_n200_edge_sweep": edge_df[edge_df["Algorithm"] == algo]["MeanTime"].mean() if not edge_df[edge_df["Algorithm"] == algo].empty else None,
        })

    out_df = pd.DataFrame(rows)
    out_df.to_csv(OUTPUT_FILE, index=False)
    print(f"Saved empirical complexity summary -> {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
